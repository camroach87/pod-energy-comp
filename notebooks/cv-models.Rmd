---
title: "Fit demand model"
author: "Cameron Roach"
date: "17/02/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(lubridate)
library(lightgbm)
library(podEnergyComp)

c_idx <- 1:31
d_idx <- 32:42
lambda_values <- cumsum(seq(0.1, 0.7, by = 0.1))
```

# Intro

## Engineer features

Using separate data frames for PV and demand. Experimenting with 6 weather stations for demand, but may want to test if only four land locations are useful. Confident that PV only affected by closest two weather stations (location 1 and 2). However, should probably do a proper test with all 6 stations again, similar to demand.

## TODO

* Still need to add public holidays.
* Investigate impact of daylight savings.

# Demand

```{r}
# Load all data and lags. Then split into the different training sets for models.
# TODO: I should create a demand class where data, cv, etc. are all attributes/methods.
demand.data <- load_demand_data("../inst/extdata/pod_ds_task1")
```



## Cross-validation

```{r message=FALSE, warning=FALSE}
demand.cv <- cv_ts_folds(
  demand.data$datetime,
  start_date = max(demand.data$datetime) + minutes(30) - days(7*10),
  horizon = 7,
  iterations = 10
)

demand.test_pred <- list()
list_idx <- 1
for (lambda_l1 in lambda_values) {
  for (i in seq_along(demand.cv)) {
    pred <- pred_demand(
      demand.data,
      demand.cv[[i]]$train,
      demand.cv[[i]]$test,
      lambda_l1 = lambda_l1
    )
    
    demand.test_pred[[list_idx]] <- tibble(
      datetime = getElement(demand.data[demand.cv[[i]]$test,], "datetime"),
      demand_mw = getElement(demand.data[demand.cv[[i]]$test,], "demand_mw"),
      pred_demand_mw = pred,
      iter = i,
      lambda_l1 = lambda_l1
    ) %>% 
      mutate(idx = row_number())  # useful for plotting
    
    list_idx <- list_idx + 1
  }
}

demand.test_pred <- bind_rows(demand.test_pred)
```



```{r}
results <- demand.test_pred %>% 
  mutate(e = demand_mw - pred_demand_mw,
         ae = abs(e)) %>% 
  group_by(lambda_l1) %>% 
  summarise(mae = mean(ae),
            rmse = sqrt(mean(e^2)))
results

best_lambda_l1 <- results %>% 
  filter(mae == min(mae)) %>% 
  pull(lambda_l1)

demand.test_pred %>% 
  filter(lambda_l1 == best_lambda_l1) %>% 
  pivot_longer(cols = contains("_mw")) %>% 
  ggplot(aes(x = idx, y = value, colour = name)) + 
  geom_line() + 
  facet_wrap(~iter) +
  labs(title = "Predictions and actuals for cross validation iterations",
       subtitle = paste0("lambda_l1 = ", best_lambda_l1))
```


Best result appears to be when $\lambda_{\mathcal{L}1} = 1.0$.


# Fit PV model

Test using all weather stations for PV.

Only using last 4 half-hourly lags. For example, doesn't make sense to base PV generation today off solar irradiance yesterday. However, half-hourly lags could be useful for picking up cloud coverage at nearby weather stations (that may move towards solar panel location).

```{r message=FALSE, warning=FALSE}
pv.data <- load_pv_data("../inst/extdata/pod_ds_task1")

pv.cv <- cv_ts_folds(
  pv.data$datetime,
  start_date = max(pv.data$datetime) + minutes(30) - days(7*10),
  horizon = 7,
  iterations = 10
)

pv.test_pred <- list()
list_idx <- 1
for (lambda_l1 in lambda_values) {
  for (i in seq_along(pv.cv)) {
    pred <- pred_pv(
      pv.data,
      pv.cv[[i]]$train,
      pv.cv[[i]]$test,
      lambda_l1 = lambda_l1
    )
    
    pv.test_pred[[list_idx]] <- tibble(
      datetime = getElement(pv.data[pv.cv[[i]]$test,], "datetime"),
      pv_power_mw = getElement(pv.data[pv.cv[[i]]$test,], "pv_power_mw"),
      pred_pv_power_mw = pred,
      iter = i,
      lambda_l1 = lambda_l1
    ) %>% 
      mutate(idx = row_number())  # useful for plotting
    
    list_idx <- list_idx + 1
  }
}

pv.test_pred <- bind_rows(pv.test_pred)

results <- pv.test_pred %>% 
  mutate(e = pv_power_mw - pred_pv_power_mw,
         ae = abs(e)) %>% 
  group_by(lambda_l1) %>% 
  summarise(mae = mean(ae),
            rmse = sqrt(mean(e^2)))
results

best_lambda_l1 <- results %>% 
  filter(mae == min(mae)) %>% 
  pull(lambda_l1)

pv.test_pred %>% 
  filter(lambda_l1 == best_lambda_l1) %>% 
  pivot_longer(cols = contains("_mw")) %>% 
  ggplot(aes(x = idx, y = value, colour = name)) + 
  geom_line() + 
  facet_wrap(~iter) +
  labs(title = "Predictions and actuals for cross validation iterations",
       subtitle = paste0("lambda_l1 = ", best_lambda_l1))
```

Best result appears to be when $\lambda_{\mathcal{L}1} = 2.1$.

Test only using closest two stations for PV.

```{r message=FALSE, warning=FALSE}
pv.data <- load_pv_data("../inst/extdata/pod_ds_task1")

pv.test_pred <- list()
list_idx <- 1
for (lambda_l1 in lambda_values) {
  for (i in seq_along(pv.cv)) {
    pred <- pred_pv(
      pv.data,
      pv.cv[[i]]$train,
      pv.cv[[i]]$test,
      lambda_l1 = lambda_l1
    )
    
    pv.test_pred[[list_idx]] <- tibble(
      datetime = getElement(pv.data[pv.cv[[i]]$test,], "datetime"),
      pv_power_mw = getElement(pv.data[pv.cv[[i]]$test,], "pv_power_mw"),
      pred_pv_power_mw = pred,
      iter = i,
      lambda_l1 = lambda_l1
    ) %>% 
      mutate(idx = row_number())  # useful for plotting
    
    list_idx <- list_idx + 1
  }
}

pv.test_pred <- bind_rows(pv.test_pred)

results <- pv.test_pred %>% 
  mutate(e = pv_power_mw - pred_pv_power_mw,
         ae = abs(e)) %>% 
  group_by(lambda_l1) %>% 
  summarise(mae = mean(ae),
            rmse = sqrt(mean(e^2)))
results

best_lambda_l1 <- results %>% 
  filter(mae == min(mae)) %>% 
  pull(lambda_l1)

pv.test_pred %>% 
  filter(lambda_l1 == best_lambda_l1) %>% 
  pivot_longer(cols = contains("_mw")) %>% 
  ggplot(aes(x = idx, y = value, colour = name)) + 
  geom_line() + 
  facet_wrap(~iter) +
  labs(title = "Predictions and actuals for cross validation iterations",
       subtitle = paste0("lambda_l1 = ", best_lambda_l1))
```

Best result appears to be when $\lambda_{\mathcal{L}1} = 0.3$.
